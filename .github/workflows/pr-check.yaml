# This GitHub Action checks incoming TidyTuesday dataset submissions.
# It verifies that all required files are present, images meet size and 
# dimension constraints, and provided URLs are accessible. Coded with the help 
# of Google Gemini.

name: PR Submission Check

on:
  pull_request:
    branches:
      - main
    paths:
      - 'data/curated/**'
  workflow_dispatch:
    inputs:
      pr_number:
        description: 'Pull Request number to check'
        required: true

jobs:
  check-submission:
    runs-on: ubuntu-latest
    
    steps:
      - name: Determine PR Number
        id: pr_num
        run: |
          # Use the PR number from the event trigger if available,
          # otherwise use the manually entered number.
          if [ -n "${{ github.event.pull_request.number }}" ]; then
            PR_NUMBER=${{ github.event.pull_request.number }}
          else
            PR_NUMBER=${{ github.event.inputs.pr_number }}
          fi
          echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT

      # For pull_request events, the action automatically checks out the PR's merge commit.
      # For workflow_dispatch, we explicitly check out the PR branch head.
      - name: Checkout PR Code
        uses: actions/checkout@v5
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && format('refs/pull/{0}/head', github.event.inputs.pr_number) || '' }}

      - name: Set up R
        uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - name: Install R dependencies
        run: |
          install.packages("pak")
          pak::pak(c("yaml", "fs", "magick", "purrr", "stringr", "glue", "httr"))
        shell: Rscript {0}

      - name: Identify Submission Directory
        id: find_dir
        run: |
          PR_NUMBER=${{ steps.pr_num.outputs.pr_number }}
          echo "Processing PR #${PR_NUMBER}"

          # Get a list of files changed in the PR, filter for the submission
          # directory, find the unique directory name.
          # The `|| true` prevents the pipe from failing if grep finds no matches.
          SUBMISSION_DIR=$(gh pr view $PR_NUMBER --json files --jq '.files[].path' | \
            grep '^data/curated/' || true | \
            xargs -r -n 1 dirname | \
            sort | \
            uniq)

          # The PR should only contain files in ONE new directory.
          if [ -z "$SUBMISSION_DIR" ] || [ $(echo "$SUBMISSION_DIR" | wc -l) -ne 1 ]; then
            echo "::error::PR must contain files in exactly one new directory under data/curated/."
            exit 1
          fi

          # Make the directory path available to subsequent steps.
          echo "submission_dir=$SUBMISSION_DIR" >> $GITHUB_OUTPUT
          echo "Found submission directory: $SUBMISSION_DIR"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Run Submission Checks
        id: run_checks
        env:
          SUBMISSION_DIR: ${{ steps.find_dir.outputs.submission_dir }}
        shell: Rscript {0}
        run: |
          # --- Script Setup ---
          # This R script runs all the checks on the submission files.
          submission_dir <- Sys.getenv("SUBMISSION_DIR")
          errors <- c() # A vector to collect all identified errors.
          cat(paste("Running checks on directory:", submission_dir, "\n"))

          # Helper function to check URL accessibility
          check_url <- function(url, source_name) {
            if (is.null(url) || !is.character(url) || nchar(url) == 0) {
              return(NULL) # No URL to check
            }
            
            message <- NULL
            tryCatch({
              # Use a HEAD request for efficiency. Set a 10-second timeout.
              response <- httr::HEAD(url, httr::timeout(10))
              # Check for client (4xx) or server (5xx) errors.
              if (httr::http_error(response)) {
                status <- httr::status_code(response)
                message <- glue::glue("URL for '{source_name}' seems to be broken (Status: {status}). Please check manually: {url}")
              }
            }, error = function(e) {
              # This catches lower-level errors like timeouts, DNS resolution failures, etc.
              message <<- glue::glue("Could not reach URL for '{source_name}'. It may be unreachable. Please check manually: {url}")
            })
            
            return(message)
          }

          # --- 1. Check for required files ---
          cat("1. Checking for required files...\n")
          required_files <- c("meta.yaml", "cleaning.R", "intro.md")
          for (f in required_files) {
            file_path <- fs::path(submission_dir, f)
            if (!fs::file_exists(file_path)) {
              errors <- c(errors, glue::glue("Missing required file: {f}"))
            }
          }

          # Check for at least one PNG file.
          png_files <- fs::dir_ls(submission_dir, glob = "*.png")
          if (length(png_files) == 0) {
            errors <- c(errors, "Missing required file: At least one *.png image is required.")
          }

          # Check for data dictionaries (*.md) for each data file (*.csv).
          csv_files <- fs::dir_ls(submission_dir, glob = "*.csv")
          if (length(csv_files) > 0) {
            for (csv_file in csv_files) {
              md_file <- fs::path_ext_set(csv_file, ".md")
              if (!fs::file_exists(md_file)) {
                errors <- c(errors, glue::glue("Missing data dictionary for {fs::path_file(csv_file)}. Expected {fs::path_file(md_file)}."))
              }
            }
          } else {
             errors <- c(errors, "Missing required file: At least one *.csv data file is required.")
          }


          # --- 2. Check meta.yaml content and linked files ---
          cat("2. Checking meta.yaml content...\n")
          meta_path <- fs::path(submission_dir, "meta.yaml")

          if (fs::file_exists(meta_path)) {
            metadata <- yaml::read_yaml(meta_path)

            # Check URLs from meta.yaml
            article_url_error <- check_url(metadata$article$url, "article")
            if (!is.null(article_url_error)) {
              errors <- c(errors, article_url_error)
            }
            datasource_url_error <- check_url(metadata$data_source$url, "data_source")
            if (!is.null(datasource_url_error)) {
              errors <- c(errors, datasource_url_error)
            }

            # Check image specifications from meta.yaml
            if (!is.null(metadata$images) && is.list(metadata$images)) {
              # Define constraints.
              max_bsky_size_kb <- 976.56
              max_bsky_size <- fs::fs_bytes(paste0(max_bsky_size_kb, "KB"))
              max_mastodon_megapix <- 8.3

              image_info_list <- metadata$images
              for (img_item in image_info_list) {
                img_path <- fs::path(submission_dir, img_item$file)
                if (!fs::file_exists(img_path)) {
                  errors <- c(errors, glue::glue("Image file '{img_item$file}' listed in meta.yaml does not exist."))
                  next # Skip to next image if this one is missing.
                }

                # Read image and get its properties.
                img <- magick::image_read(img_path)
                info <- magick::image_info(img)

                # Check 1: Filesize for Bluesky compatibility.
                filesize_kb <- info$filesize / 1024
                if (info$filesize > max_bsky_size) {
                  errors <- c(
                    errors,
                    glue::glue("Image '{img_item$file}' is too large. Size is {round(filesize_kb, 2)} KB, max is {max_bsky_size_kb} KB.")
                  )
                }

                # Check 2: Megapixels for Mastodon compatibility.
                megapix <- info$width * info$height / 1e6
                if (megapix > max_mastodon_megapix) {
                  errors <- c(
                    errors,
                    glue::glue("Image '{img_item$file}' has too many megapixels. It is {round(megapix, 2)} MP, max is {max_mastodon_megapix} MP.")
                  )
                }
              }
            } else {
               errors <- c(errors, "'images' section is missing or malformed in meta.yaml.")
            }
          }

          # --- 3. Final Report ---
          # After all checks, prepare the report for commenting.
          cat("3. Preparing report...\n")
          report_file <- "pr_comment.md"
          
          if (length(errors) > 0) {
            header <- "### TidyTuesday Submission Check: Failed ❌\n\nFound the following issues with the submission:\n"
            error_list <- paste0("- ", errors, collapse = "\n")
            report_body <- paste0(header, error_list)
            check_status <- "failure"
          } else {
            report_body <- "### TidyTuesday Submission Check: Passed ✅\n\nAll checks passed successfully!"
            check_status <- "success"
          }
          
          writeLines(report_body, report_file)
          cat(paste("Report written to", report_file, "\n"))
          
          # Set outputs for subsequent steps
          write(paste0("check_status=", check_status), file = Sys.getenv("GITHUB_OUTPUT"))

      - name: Comment on PR
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const commentBody = fs.readFileSync('pr_comment.md', 'utf8');

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: ${{ steps.pr_num.outputs.pr_number }},
              body: commentBody
            });

      - name: Fail workflow if checks failed
        if: steps.run_checks.outputs.check_status == 'failure'
        run: exit 1
